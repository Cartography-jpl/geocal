#! /usr/bin/env python
from geocal import *
import os
import logging
import math

version = "September 16, 2013"
usage='''Usage: 
  write_image [options] <input_image> <output_image>...
  write_image [options] --subset <start_line> <start_sample>
      <number_line> <number_sample> <input_image> <output_image>...
  write_image -h | --help
  write_image -v | --version

This program is used write to a VICAR image. The input is an image as
a sqlite shelve object in the "file:key" format", e.g.,
"my_data.db:image".  The input image might require a calculation to
generate the results, e.g., it is a scaled image.

The image can also be a MultiBandRasterImage, in which case you need to
specify as many output images as there are bands in the multi band image.

The data can be generate in parallel. Depending on the environment, you
can do the parallel generation in 1 of a few ways:

1. Run this program in parallel. Requires that all the CPUs use the same
   shared memory space (e.g., a single multi core machine).
2. Set up go use gnu parallel program. This is useful if you are using a
   cluster of CPUs (e.g., a few difference machines in a cluster).
3. Set up to use torque job processing. This is useful for very large jobs
   that take a long time to run (e.g., full resolution DSM generation).

Options:
  -h --help         
       Print this message

  --gnu-parallel
       Set up to using gnu parallel program, including generating a script
       for this. We do not actually run the script.

  --log-file=f
       File name to use as a log file.

  --no-data-value=n
       Value to indicate no data. This is just set as metadata for the
       output file, it doesn't affect the generation of the image at all.

  --number-process=n
       Number of processors to use. [default: 1]

  --process-number-line=n
       Number of lines to include in each tile that we work on. This 
       controls how long each torque/parallel job takes to run. If
       not supplied, we just divide the total image size by the number
       of processes we are using.

  --process-number-sample=n
       Number of lines to include in each tile that we work on. This 
       controls how long each torque/parallel job takes to run. If
       not supplied, we use the total image size.

  --scale=f
       Factor to scale image by. This can be particularly useful when you
       are mapping float data to an integer type like HALF (e.g., reflectance
       from 0.0 to 1.0 expressed as a HALF VICAR file).

  --subset
       Subset the input image.

  --torque
       Set up to using torque, including generating a script for this. We 
       do not actually run the script to submit the jobs.

  --vicar-type=type
       Type of file to generate. This should by BYTE, HALF, FULL, REAL, or
       DOUB. [default: HALF]

  --verbose
       Print more information as we run.

  -v --version      
       Print program version
'''

args = docopt_simple(usage, version=version)
if(args.log_file):
    logging.basicConfig(level = logging.INFO,
                        format = '%(asctime)s %(levelname)s:%(name)s:%(message)s',
                        filename = args.log_file)
    if(args.verbose):
        console = logging.StreamHandler(stream=sys.stdout)
        console.setLevel(logging.INFO)
        console.setFormatter(logging.Formatter('%(levelname)s:%(name)s:%(message)s'))
        logging.getLogger("geocal-python").addHandler(console)
elif(args.verbose):
    logging.basicConfig(level = logging.INFO)
log = logging.getLogger("geocal-python.write_image")

img_in = read_shelve(args.input_image)
if(args.start_line):
    if(isinstance(img_in, RasterImageMultiBand)):
        img_in = img_in.subset(args.start_line, args.start_sample,
                               args.number_line, args.number_sample)
    else:
        img_in = SubRasterImage(img_in, args.start_line, args.start_sample,
                                args.number_line, args.number_sample)
if(args.scale):
    if(isinstance(img_in, RasterImageMultiBand)):
        img_in = ScaleImageMultiBand(img_in, args.scale)
    else:
        img_in = ScaleImage(img_in, args.scale)

img_list = []
if(isinstance(img_in, RasterImageMultiBand)):
    for i in range(img_in.number_band):
        img_list.append(img_in.raster_image(i))
else:
    img_list.append(img_in)

out_list = []
for i, img in enumerate(img_list):
    out = VicarRasterImage(args.output_image[i], args.vicar_type, 
                           img.number_line, img.number_sample)
    if(img.has_map_info):
        out.set_map_info(img.map_info)
    if(img.has_rpc):
        out.set_rpc(img.rpc)
    if(args.no_data_value is not None):
        out["NODATA"] = float(args.no_data_value)
    out.close()
    out_list.append(mmap_file(args.output_image[i], mode="r+"))

if(not isinstance(img_in, RasterImageMultiBand)):
    out_list = out_list[0]

if(args.process_number_line is not None):
    process_nline = args.process_number_line
else:
    process_nline = int(math.ceil(float(img_list[0].number_line) / args.number_process))
if(args.process_number_sample is not None):
    process_nsamp = args.process_number_sample
else:
    process_nsamp = img_list[0].number_sample
if(args.torque or args.gnu_parallel):
    base_name = os.path.splitext(args.output_image[0])[0]
    shelve_name =  base_name + ".db"
    try:
        os.remove(shelve_name)
    except OSError as exc:
        pass                    # Ok if doesn't exist
else:
    shelve_name = None
    
number_job = parallel_process_image(img_in, out_list, process_nline, 
                                    process_nsamp, 
                                    args.number_process, 
                                    shelve_name = shelve_name)
if(args.torque):
# Create a script that can submit these jobs
    log_dir = base_name + "_log"
    shelve_job_run = subprocess.check_output(["which", "shelve_job_run"]).replace("\n", "")
    pythonpath = os.environ["PYTHONPATH"]
    makedirs_p(log_dir)
    job_script = '''#!/bin/bash
if [[ $# -lt 1 ]]; then
   echo "Usage: $0 <arguments to qsub>"
   echo ""
   echo 'At a minimum, you need to supply the queue to use, e.g., "-q long"'
   exit 1
fi
export SHELVE_DATABASE_FILE="{shelve_name}"
export PYTHONPATH={pythonpath}

jid=`qsub -d {work_dir} -V -j oe -o {log_dir}/qsub.log -N write_image -t 0-{max_array_num} {shelve_job_run} $*`
# Add anything you want to follow this job here, e.g., using 
# qsub -d {work_dir} -V -j oe -o {log_dir}/qsub.log -W depend=afterokarray:$jid blah
'''
    with open(base_name + ".job_script", "w") as f:
        f.write(job_script.format\
                    (shelve_name=shelve_name,
                     pythonpath=pythonpath,
                     log_dir=log_dir,
                     shelve_job_run=shelve_job_run,
                     max_array_num=number_job,
                     work_dir = os.path.abspath(os.path.dirname(shelve_name)),
                     ))
    os.chmod(base_name + ".job_script", 0o755)
    print("Run %s to submit jobs to torque" % (base_name + ".job_script"))

if(args.gnu_parallel):
# Create a script that can submit these jobs
    job_script = '''#!/bin/sh
seq 0 {max_num} | parallel --gnu -u shelve_job_run {shelve_name} {{}}
'''
    with open(base_name + ".sh", "w") as f:
        f.write(job_script.format\
                    (shelve_name=shelve_name,
                     max_num=number_job - 1,
                     ))
    os.chmod(base_name + ".sh", 0o755)
    print("Run %s to jobs using gnu parallel" % (base_name + ".sh"))

logging.shutdown()

                     
    
